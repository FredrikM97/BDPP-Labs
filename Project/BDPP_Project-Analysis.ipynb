{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "file = \"data/US_Accidents_Dec19.csv\"\n",
    "model_indexing_dir = \"log_index.md\"\n",
    "timeSignature = str(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "models_dir = \"models\"\n",
    "model_Note = 'Analysis tool'\n",
    "images_dir = \"analysis\"\n",
    "enabled = False\n",
    "logger = logging(\"analysis\", \"analysis/logs.md\", \"analysis\", str(timeSignature), enabled=enabled)\n",
    "\n",
    "df,sc, spark = setup_spark(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://97901d576ca5:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Spark Project>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: [('spark.driver.memory', '4g'), ('spark.executor.memory', '4g'), ('spark.app.id', 'local-1588768733966'), ('spark.ui.enabled', 'true'), ('spark.executor.id', 'driver'), ('spark.app.name', 'Spark Project'), ('spark.ui.killEnabled', 'false'), ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'), ('spark.driver.host', '97901d576ca5'), ('spark.driver.port', '40147'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.executor.instances', '1'), ('spark.master', 'local[*]'), ('spark.executor.cores', '1'), ('spark.submit.deployMode', 'client'), ('spark.kryoserializer.buffer.max', '15'), ('spark.ui.showConsoleProgress', 'true'), ('spark.driver.cores', '1')]\n"
     ]
    }
   ],
   "source": [
    "tmp = sc._conf.getAll()\n",
    "logger.write2file(\"New Spark session\", str(tmp))\n",
    "print(\"Config:\",tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ['Street', 'Side', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight'] \n",
      "Categories: ['Street', 'Side', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
      "Numerical: ['TMC', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Number', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n"
     ]
    }
   ],
   "source": [
    "colLabel = [\"Severity\"]\n",
    "\n",
    "colRem = ['ID', \n",
    "          'Source',\n",
    "          'End_Time',\n",
    "          'End_Lat',\n",
    "          'End_Lng',\n",
    "          'Description',\n",
    "        ]\n",
    "\n",
    "df, colCat, colNum = setup_variables(df, sc, colLabel, colRem)    \n",
    "\n",
    "logger.write2file(\"Number of rows\", str(df.count()))\n",
    "logger.write2file(\"Categorical groups\",\"Defined Label:\\n\" + str(colLabel) + \"\\nDefined Categories:\\n\" + str(colCat) + \"\\nDefined Numerical:\\n\" +str(colNum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      " Labels: 1\n",
      " Classes: 28\n",
      " Removed: 6\n",
      " Numerical: 12\n",
      "Rows: 2974335\n",
      "Columns 43\n",
      "root\n",
      " |-- TMC: double (nullable = true)\n",
      " |-- Severity: integer (nullable = true)\n",
      " |-- Start_Time: timestamp (nullable = true)\n",
      " |-- Start_Lat: double (nullable = true)\n",
      " |-- Start_Lng: double (nullable = true)\n",
      " |-- Distance(mi): double (nullable = true)\n",
      " |-- Number: double (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Side: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Timezone: string (nullable = true)\n",
      " |-- Airport_Code: string (nullable = true)\n",
      " |-- Weather_Timestamp: timestamp (nullable = true)\n",
      " |-- Temperature(F): double (nullable = true)\n",
      " |-- Wind_Chill(F): double (nullable = true)\n",
      " |-- Humidity(%): double (nullable = true)\n",
      " |-- Pressure(in): double (nullable = true)\n",
      " |-- Visibility(mi): double (nullable = true)\n",
      " |-- Wind_Direction: string (nullable = true)\n",
      " |-- Wind_Speed(mph): double (nullable = true)\n",
      " |-- Precipitation(in): double (nullable = true)\n",
      " |-- Weather_Condition: string (nullable = true)\n",
      " |-- Amenity: string (nullable = true)\n",
      " |-- Bump: string (nullable = true)\n",
      " |-- Crossing: string (nullable = true)\n",
      " |-- Give_Way: string (nullable = true)\n",
      " |-- Junction: string (nullable = true)\n",
      " |-- No_Exit: string (nullable = true)\n",
      " |-- Railway: string (nullable = true)\n",
      " |-- Roundabout: string (nullable = true)\n",
      " |-- Station: string (nullable = true)\n",
      " |-- Stop: string (nullable = true)\n",
      " |-- Traffic_Calming: string (nullable = true)\n",
      " |-- Traffic_Signal: string (nullable = true)\n",
      " |-- Turning_Loop: string (nullable = true)\n",
      " |-- Sunrise_Sunset: string (nullable = true)\n",
      " |-- Civil_Twilight: string (nullable = true)\n",
      " |-- Nautical_Twilight: string (nullable = true)\n",
      " |-- Astronomical_Twilight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Categories:\\n \\\n",
    "Labels: {len(colLabel)}\\n \\\n",
    "Classes: {len(colCat)}\\n \\\n",
    "Removed: {len(colRem)}\\n \\\n",
    "Numerical: {len(colNum)}\") \n",
    "\n",
    "info = f\"Rows: {df.count()}\\nColumns {len(df.columns)}\"\n",
    "print(info)\n",
    "df.printSchema()\n",
    "df.take(1)\n",
    "\n",
    "logger.write2file(\"Data analysis\",info +\"\\n\"+ str(df._jdf.schema().treeString()) + str(df.take(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+--------------------+\n",
      "|summary|               TMC|         Start_Lat|         Start_Lng|      Distance(mi)|            Number|   Temperature(F)|    Wind_Chill(F)|       Humidity(%)|      Pressure(in)|   Visibility(mi)|  Wind_Speed(mph)|   Precipitation(in)|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+--------------------+\n",
      "|  count|           2246264|           2974335|           2974335|           2974335|           1056730|          2918272|          1121712|           2915162|           2926193|          2908644|          2533495|              975977|\n",
      "|   mean|207.83163198982845|36.493605002031636| -95.4262537385967|0.2855653569462957| 5837.003543951624|62.35120314350398|51.32684860284989| 65.40541554808961|29.831895008292193| 9.15076997047429|8.298063781457618|0.020494509604222225|\n",
      "| stddev| 20.32958633116194| 4.918848998696759|17.218805933372185|1.5483920254566632|15159.278074287868|18.78854911265782|25.19127055656769|22.556763456537613|0.7213808414176774|2.892113743736492|5.138545725098774| 0.23577039560945023|\n",
      "|    min|             200.0|         24.555269|       -124.623833|               0.0|               0.0|            -77.8|            -65.9|               1.0|               0.0|              0.0|              0.0|                 0.0|\n",
      "|    max|             406.0|         49.002201|        -67.113167|     333.630004883|         9999997.0|            170.6|            115.0|             100.0|             33.04|            140.0|            822.8|                25.0|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(colNum).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values[Row(TMC=728071, Severity=0, Start_Time=0, Start_Lat=0, Start_Lng=0, Distance(mi)=0, Number=1917605, Street=0, Side=0, City=83, County=0, State=0, Zipcode=880, Country=0, Timezone=3163, Airport_Code=5691, Weather_Timestamp=36705, Temperature(F)=56063, Wind_Chill(F)=1852623, Humidity(%)=59173, Pressure(in)=48142, Visibility(mi)=65691, Wind_Direction=45101, Wind_Speed(mph)=440840, Precipitation(in)=1998358, Weather_Condition=65932, Amenity=0, Bump=0, Crossing=0, Give_Way=0, Junction=0, No_Exit=0, Railway=0, Roundabout=0, Station=0, Stop=0, Traffic_Calming=0, Traffic_Signal=0, Turning_Loop=0, Sunrise_Sunset=93, Civil_Twilight=93, Nautical_Twilight=93, Astronomical_Twilight=93)]\n"
     ]
    }
   ],
   "source": [
    "printMissingValues(df, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique column values: [Row(Street=160715), Row(Side=3), Row(City=11685), Row(County=1713), Row(State=49), Row(Zipcode=377152), Row(Country=1), Row(Timezone=4), Row(Airport_Code=1995), Row(Wind_Direction=24), Row(Weather_Condition=120), Row(Amenity=2), Row(Bump=2), Row(Crossing=2), Row(Give_Way=2), Row(Junction=2), Row(No_Exit=2), Row(Railway=2), Row(Roundabout=2), Row(Station=2), Row(Stop=2), Row(Traffic_Calming=2), Row(Traffic_Signal=2), Row(Turning_Loop=1), Row(Sunrise_Sunset=2), Row(Civil_Twilight=2), Row(Nautical_Twilight=2), Row(Astronomical_Twilight=2)]\n"
     ]
    }
   ],
   "source": [
    "df.persist()\n",
    "tmp = [df.select(countDistinct(c).alias(c)).collect()[0] for c in [*colCat]] \n",
    "df.unpersist()\n",
    "print(\"Unique column values:\", tmp)\n",
    "\n",
    "logger.write2file(\"Unique column values\", str(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TMC', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Number', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)', 'Severity']\n"
     ]
    }
   ],
   "source": [
    "print([*colNum, *colLabel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n",
      "|features                                                                   |\n",
      "+---------------------------------------------------------------------------+\n",
      "|[201.0,39.972038,-82.913521,0.01,3280.0,37.4,33.8,100.0,29.62,3.0,4.6,0.02]|\n",
      "+---------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "correlation matrix:\n",
      "DenseMatrix([[ 1.00000000e+00, -3.29968079e-02, -4.23709318e-02,\n",
      "               6.48521350e-02,  4.88102771e-02,  2.89427459e-02,\n",
      "               3.07391705e-02, -6.70493470e-03,  4.59513996e-03,\n",
      "               2.21819466e-02, -1.61669692e-03, -1.80310455e-03],\n",
      "             [-3.29968079e-02,  1.00000000e+00, -5.22492702e-03,\n",
      "               5.01751676e-02, -3.17558810e-02, -4.68351247e-01,\n",
      "              -4.69159899e-01,  9.79378608e-02, -1.18202158e-01,\n",
      "              -1.54998940e-01,  9.15359600e-02,  5.03876348e-03],\n",
      "             [-4.23709318e-02, -5.22492702e-03,  1.00000000e+00,\n",
      "              -7.53412624e-03, -1.85446020e-01, -6.29347088e-02,\n",
      "              -7.17865446e-02,  1.97789478e-01,  2.74148682e-01,\n",
      "              -8.96066993e-02,  3.69653763e-02,  1.71422780e-02],\n",
      "             [ 6.48521350e-02,  5.01751676e-02, -7.53412624e-03,\n",
      "               1.00000000e+00,  2.39536246e-02, -2.59661162e-02,\n",
      "              -2.52581670e-02,  1.25991397e-02, -4.31332807e-02,\n",
      "              -1.74274857e-03, -3.02094605e-05,  5.51084719e-04],\n",
      "             [ 4.88102771e-02, -3.17558810e-02, -1.85446020e-01,\n",
      "               2.39536246e-02,  1.00000000e+00,  9.15996465e-03,\n",
      "               1.14585147e-02, -5.41486806e-03, -3.01287122e-02,\n",
      "               1.54279877e-02, -1.55270941e-02, -3.57307853e-03],\n",
      "             [ 2.89427459e-02, -4.68351247e-01, -6.29347088e-02,\n",
      "              -2.59661162e-02,  9.15996465e-03,  1.00000000e+00,\n",
      "               9.94635527e-01, -4.33436493e-01, -5.74036079e-02,\n",
      "               3.59398479e-01, -5.70376387e-02, -3.18768976e-02],\n",
      "             [ 3.07391705e-02, -4.69159899e-01, -7.17865446e-02,\n",
      "              -2.52581670e-02,  1.14585147e-02,  9.94635527e-01,\n",
      "               1.00000000e+00, -4.17693108e-01, -6.40984846e-02,\n",
      "               3.71812190e-01, -1.07307690e-01, -3.27164732e-02],\n",
      "             [-6.70493470e-03,  9.79378608e-02,  1.97789478e-01,\n",
      "               1.25991397e-02, -5.41486806e-03, -4.33436493e-01,\n",
      "              -4.17693108e-01,  1.00000000e+00,  2.37124810e-01,\n",
      "              -4.32133625e-01, -1.32366631e-01,  7.35304410e-02],\n",
      "             [ 4.59513996e-03, -1.18202158e-01,  2.74148682e-01,\n",
      "              -4.31332807e-02, -3.01287122e-02, -5.74036079e-02,\n",
      "              -6.40984846e-02,  2.37124810e-01,  1.00000000e+00,\n",
      "              -1.45464758e-01, -2.46856204e-02,  1.82447540e-02],\n",
      "             [ 2.21819466e-02, -1.54998940e-01, -8.96066993e-02,\n",
      "              -1.74274857e-03,  1.54279877e-02,  3.59398479e-01,\n",
      "               3.71812190e-01, -4.32133625e-01, -1.45464758e-01,\n",
      "               1.00000000e+00, -4.80546183e-02, -1.11093421e-01],\n",
      "             [-1.61669692e-03,  9.15359600e-02,  3.69653763e-02,\n",
      "              -3.02094605e-05, -1.55270941e-02, -5.70376387e-02,\n",
      "              -1.07307690e-01, -1.32366631e-01, -2.46856204e-02,\n",
      "              -4.80546183e-02,  1.00000000e+00,  2.50120835e-02],\n",
      "             [-1.80310455e-03,  5.03876348e-03,  1.71422780e-02,\n",
      "               5.51084719e-04, -3.57307853e-03, -3.18768976e-02,\n",
      "              -3.27164732e-02,  7.35304410e-02,  1.82447540e-02,\n",
      "              -1.11093421e-01,  2.50120835e-02,  1.00000000e+00]])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=colNum,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid = \"skip\")\n",
    "\n",
    "df_attributes = assembler.transform(df)\n",
    "df_attributes.select(\"features\").show(1,False)\n",
    "\n",
    "\n",
    "\n",
    "r1 = Correlation.corr(df_attributes, \"features\").head()\n",
    "\n",
    "print(\"correlation matrix:\\n\" + str(r1[0]))\n",
    "\n",
    "logger.write2file(\"Correlation matrix\", str(r1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    sns.set(style=\"white\")\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    b = sns.heatmap(r1[0].toArray().tolist(), annot=True, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5},xticklabels=colNum,yticklabels=colNum,ax=ax )\n",
    "    ax.set_title(\"Correlation between numerical features\")\n",
    "\n",
    "    logger.saveImage(b,\"feature_corr_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Severity=2, count=1993410),\n",
       " Row(Severity=3, count=887620),\n",
       " Row(Severity=4, count=92337),\n",
       " Row(Severity=1, count=968)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severity_freq = df.groupBy('Severity').count().orderBy('count',ascending=False).collect()\n",
    "severity_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    rdd = sc.parallelize(severity_freq)\n",
    "    pd_severity = rdd.toDF().toPandas()\n",
    "\n",
    "    # Plot data\n",
    "    fig,ax = plt.subplots(figsize=(16,10))\n",
    "    b = sns.barplot(pd_severity['Severity'],pd_severity['count'], color='blue')\n",
    "    b.axes.set_title(\"Severity distribution\",fontsize=20)\n",
    "    b.set_xlabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.set_ylabel(\"Severity\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"severity_dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    df_sev = df.groupby('Severity').count().toPandas()\n",
    "    fig = df_sev.plot.pie(y='count', labels=df_sev['Severity'], figsize=(10, 10), autopct='%1.0f%%',title=\"Pie plot - Severity distribution\",fontsize=15)\n",
    "    fig.figure.savefig(images_dir +\"/pie_severity_dist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of severity and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(State='CA', count=663204),\n",
       " Row(State='TX', count=298062),\n",
       " Row(State='FL', count=223746),\n",
       " Row(State='SC', count=146689),\n",
       " Row(State='NC', count=142460),\n",
       " Row(State='NY', count=137799),\n",
       " Row(State='PA', count=90395),\n",
       " Row(State='MI', count=88694),\n",
       " Row(State='IL', count=86390),\n",
       " Row(State='GA', count=83620),\n",
       " Row(State='VA', count=79957),\n",
       " Row(State='OR', count=70840),\n",
       " Row(State='MN', count=62727),\n",
       " Row(State='AZ', count=62330),\n",
       " Row(State='WA', count=61367),\n",
       " Row(State='TN', count=58289),\n",
       " Row(State='OH', count=55863),\n",
       " Row(State='LA', count=52481),\n",
       " Row(State='OK', count=51297),\n",
       " Row(State='NJ', count=49942),\n",
       " Row(State='MD', count=43328),\n",
       " Row(State='UT', count=41385),\n",
       " Row(State='CO', count=40124),\n",
       " Row(State='AL', count=36369),\n",
       " Row(State='MA', count=33014),\n",
       " Row(State='IN', count=30040),\n",
       " Row(State='MO', count=29012),\n",
       " Row(State='CT', count=22803),\n",
       " Row(State='NE', count=22505),\n",
       " Row(State='KY', count=19122),\n",
       " Row(State='WI', count=17580),\n",
       " Row(State='RI', count=10483),\n",
       " Row(State='IA', count=10346),\n",
       " Row(State='NV', count=9524),\n",
       " Row(State='NH', count=7064),\n",
       " Row(State='KS', count=6887),\n",
       " Row(State='MS', count=5961),\n",
       " Row(State='NM', count=5020),\n",
       " Row(State='DE', count=4434),\n",
       " Row(State='DC', count=3653),\n",
       " Row(State='WV', count=2274),\n",
       " Row(State='ME', count=2065),\n",
       " Row(State='ID', count=1757),\n",
       " Row(State='AR', count=1749),\n",
       " Row(State='VT', count=585),\n",
       " Row(State='MT', count=504),\n",
       " Row(State='WY', count=492),\n",
       " Row(State='SD', count=60),\n",
       " Row(State='ND', count=43)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_freq = df.groupBy('State').count().orderBy('count',ascending=False).collect()\n",
    "state_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    rdd = sc.parallelize(state_freq)\n",
    "    pd_states = rdd.toDF().toPandas()\n",
    "\n",
    "    # Plot data\n",
    "    fig,ax = plt.subplots(figsize=(16,10))\n",
    "    b = sns.barplot(pd_states['State'],pd_states['count'], color='blue')\n",
    "    b.axes.set_title(\"Severity distribution for each state\",fontsize=20)\n",
    "    b.set_xlabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.set_ylabel(\"State\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"severity_dist_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(State='CA', Severity=2, count=445381),\n",
       " Row(State='TX', Severity=2, count=215027),\n",
       " Row(State='CA', Severity=3, count=211189),\n",
       " Row(State='FL', Severity=2, count=144622),\n",
       " Row(State='NC', Severity=2, count=121261),\n",
       " Row(State='SC', Severity=2, count=114339),\n",
       " Row(State='NY', Severity=2, count=82388),\n",
       " Row(State='TX', Severity=3, count=79467),\n",
       " Row(State='FL', Severity=3, count=71631),\n",
       " Row(State='PA', Severity=2, count=67778),\n",
       " Row(State='OR', Severity=2, count=61538),\n",
       " Row(State='IL', Severity=2, count=58901),\n",
       " Row(State='MI', Severity=2, count=52583),\n",
       " Row(State='NY', Severity=3, count=49968),\n",
       " Row(State='AZ', Severity=2, count=47248),\n",
       " Row(State='OK', Severity=2, count=46194),\n",
       " Row(State='VA', Severity=2, count=42556),\n",
       " Row(State='GA', Severity=3, count=42393),\n",
       " Row(State='LA', Severity=2, count=41674),\n",
       " Row(State='TN', Severity=2, count=38526),\n",
       " Row(State='WA', Severity=2, count=37528),\n",
       " Row(State='MN', Severity=2, count=37017),\n",
       " Row(State='GA', Severity=2, count=34605),\n",
       " Row(State='OH', Severity=2, count=33817),\n",
       " Row(State='NJ', Severity=2, count=33264),\n",
       " Row(State='VA', Severity=3, count=32750),\n",
       " Row(State='SC', Severity=3, count=31366),\n",
       " Row(State='MI', Severity=3, count=31361),\n",
       " Row(State='UT', Severity=2, count=29890),\n",
       " Row(State='MN', Severity=3, count=25348),\n",
       " Row(State='IL', Severity=3, count=24706),\n",
       " Row(State='AL', Severity=2, count=23906),\n",
       " Row(State='CO', Severity=2, count=21235),\n",
       " Row(State='WA', Severity=3, count=21129),\n",
       " Row(State='MD', Severity=2, count=20285),\n",
       " Row(State='MA', Severity=2, count=19907),\n",
       " Row(State='NE', Severity=2, count=18868),\n",
       " Row(State='NC', Severity=3, count=18837),\n",
       " Row(State='IN', Severity=2, count=18705),\n",
       " Row(State='MD', Severity=3, count=18341),\n",
       " Row(State='TN', Severity=3, count=18275),\n",
       " Row(State='PA', Severity=3, count=17862),\n",
       " Row(State='OH', Severity=3, count=17057),\n",
       " Row(State='CO', Severity=3, count=15699),\n",
       " Row(State='MO', Severity=3, count=15090),\n",
       " Row(State='NJ', Severity=3, count=13904),\n",
       " Row(State='MA', Severity=3, count=12839),\n",
       " Row(State='MO', Severity=2, count=12476),\n",
       " Row(State='AZ', Severity=3, count=12003),\n",
       " Row(State='AL', Severity=3, count=11931),\n",
       " Row(State='CT', Severity=2, count=10650),\n",
       " Row(State='CT', Severity=3, count=10455),\n",
       " Row(State='UT', Severity=3, count=10301),\n",
       " Row(State='LA', Severity=3, count=9887),\n",
       " Row(State='KY', Severity=2, count=9428),\n",
       " Row(State='WI', Severity=2, count=8937),\n",
       " Row(State='KY', Severity=3, count=8927),\n",
       " Row(State='IN', Severity=3, count=8826),\n",
       " Row(State='FL', Severity=4, count=7422),\n",
       " Row(State='OR', Severity=3, count=6921),\n",
       " Row(State='GA', Severity=4, count=6595),\n",
       " Row(State='CA', Severity=4, count=6388),\n",
       " Row(State='WI', Severity=3, count=6182),\n",
       " Row(State='NV', Severity=2, count=6050),\n",
       " Row(State='NH', Severity=2, count=5664),\n",
       " Row(State='NY', Severity=4, count=5421),\n",
       " Row(State='RI', Severity=3, count=5418),\n",
       " Row(State='OH', Severity=4, count=4973),\n",
       " Row(State='RI', Severity=2, count=4963),\n",
       " Row(State='IA', Severity=3, count=4828),\n",
       " Row(State='MI', Severity=4, count=4721),\n",
       " Row(State='PA', Severity=4, count=4718),\n",
       " Row(State='IA', Severity=2, count=4678),\n",
       " Row(State='OK', Severity=3, count=4677),\n",
       " Row(State='MD', Severity=4, count=4669),\n",
       " Row(State='VA', Severity=4, count=4623),\n",
       " Row(State='DE', Severity=2, count=3457),\n",
       " Row(State='TX', Severity=4, count=3448),\n",
       " Row(State='NE', Severity=3, count=3370),\n",
       " Row(State='MS', Severity=2, count=3317),\n",
       " Row(State='KS', Severity=2, count=3262),\n",
       " Row(State='KS', Severity=3, count=3246),\n",
       " Row(State='CO', Severity=4, count=3185),\n",
       " Row(State='AZ', Severity=4, count=3058),\n",
       " Row(State='NV', Severity=3, count=3043),\n",
       " Row(State='NM', Severity=2, count=2775),\n",
       " Row(State='IL', Severity=4, count=2768),\n",
       " Row(State='NJ', Severity=4, count=2753),\n",
       " Row(State='WA', Severity=4, count=2680),\n",
       " Row(State='IN', Severity=4, count=2492),\n",
       " Row(State='WI', Severity=4, count=2460),\n",
       " Row(State='DC', Severity=2, count=2382),\n",
       " Row(State='OR', Severity=4, count=2379),\n",
       " Row(State='MS', Severity=3, count=2373),\n",
       " Row(State='NC', Severity=4, count=2332),\n",
       " Row(State='NM', Severity=3, count=1917),\n",
       " Row(State='ME', Severity=2, count=1899),\n",
       " Row(State='CT', Severity=4, count=1681),\n",
       " Row(State='TN', Severity=4, count=1468),\n",
       " Row(State='MO', Severity=4, count=1439),\n",
       " Row(State='ID', Severity=2, count=1373),\n",
       " Row(State='WV', Severity=2, count=1352),\n",
       " Row(State='NH', Severity=3, count=1232),\n",
       " Row(State='UT', Severity=4, count=1191),\n",
       " Row(State='SC', Severity=4, count=944),\n",
       " Row(State='LA', Severity=4, count=901),\n",
       " Row(State='DC', Severity=3, count=867),\n",
       " Row(State='AR', Severity=2, count=860),\n",
       " Row(State='IA', Severity=4, count=837),\n",
       " Row(State='KY', Severity=4, count=760),\n",
       " Row(State='DE', Severity=4, count=574),\n",
       " Row(State='AL', Severity=4, count=514),\n",
       " Row(State='WV', Severity=3, count=467),\n",
       " Row(State='WV', Severity=4, count=454),\n",
       " Row(State='AR', Severity=4, count=450),\n",
       " Row(State='AR', Severity=3, count=439),\n",
       " Row(State='NV', Severity=4, count=430),\n",
       " Row(State='VT', Severity=2, count=414),\n",
       " Row(State='OK', Severity=4, count=411),\n",
       " Row(State='DC', Severity=4, count=403),\n",
       " Row(State='DE', Severity=3, count=400),\n",
       " Row(State='KS', Severity=4, count=379),\n",
       " Row(State='MN', Severity=4, count=353),\n",
       " Row(State='NM', Severity=4, count=327),\n",
       " Row(State='MS', Severity=4, count=270),\n",
       " Row(State='MT', Severity=2, count=263),\n",
       " Row(State='NE', Severity=4, count=255),\n",
       " Row(State='MA', Severity=4, count=253),\n",
       " Row(State='CA', Severity=1, count=246),\n",
       " Row(State='ID', Severity=4, count=195),\n",
       " Row(State='ID', Severity=3, count=189),\n",
       " Row(State='WY', Severity=4, count=187),\n",
       " Row(State='WY', Severity=3, count=176),\n",
       " Row(State='NH', Severity=4, count=166),\n",
       " Row(State='MT', Severity=3, count=135),\n",
       " Row(State='WY', Severity=2, count=129),\n",
       " Row(State='TX', Severity=1, count=120),\n",
       " Row(State='VT', Severity=3, count=111),\n",
       " Row(State='MT', Severity=4, count=106),\n",
       " Row(State='RI', Severity=4, count=102),\n",
       " Row(State='ME', Severity=4, count=97),\n",
       " Row(State='FL', Severity=1, count=71),\n",
       " Row(State='ME', Severity=3, count=68),\n",
       " Row(State='VT', Severity=4, count=59),\n",
       " Row(State='SC', Severity=1, count=40),\n",
       " Row(State='PA', Severity=1, count=37),\n",
       " Row(State='SD', Severity=4, count=35),\n",
       " Row(State='MD', Severity=1, count=33),\n",
       " Row(State='WA', Severity=1, count=30),\n",
       " Row(State='NC', Severity=1, count=30),\n",
       " Row(State='MI', Severity=1, count=29),\n",
       " Row(State='VA', Severity=1, count=28),\n",
       " Row(State='GA', Severity=1, count=27),\n",
       " Row(State='NY', Severity=1, count=22),\n",
       " Row(State='AZ', Severity=1, count=21),\n",
       " Row(State='NJ', Severity=1, count=21),\n",
       " Row(State='ND', Severity=2, count=21),\n",
       " Row(State='TN', Severity=1, count=20),\n",
       " Row(State='LA', Severity=1, count=19),\n",
       " Row(State='AL', Severity=1, count=18),\n",
       " Row(State='CT', Severity=1, count=17),\n",
       " Row(State='IN', Severity=1, count=17),\n",
       " Row(State='SD', Severity=2, count=17),\n",
       " Row(State='OH', Severity=1, count=16),\n",
       " Row(State='MA', Severity=1, count=15),\n",
       " Row(State='OK', Severity=1, count=15),\n",
       " Row(State='IL', Severity=1, count=15),\n",
       " Row(State='NE', Severity=1, count=12),\n",
       " Row(State='ND', Severity=3, count=11),\n",
       " Row(State='ND', Severity=4, count=11),\n",
       " Row(State='MN', Severity=1, count=9),\n",
       " Row(State='SD', Severity=3, count=8),\n",
       " Row(State='KY', Severity=1, count=7),\n",
       " Row(State='MO', Severity=1, count=7),\n",
       " Row(State='CO', Severity=1, count=5),\n",
       " Row(State='DE', Severity=1, count=3),\n",
       " Row(State='IA', Severity=1, count=3),\n",
       " Row(State='UT', Severity=1, count=3),\n",
       " Row(State='NH', Severity=1, count=2),\n",
       " Row(State='OR', Severity=1, count=2),\n",
       " Row(State='NV', Severity=1, count=1),\n",
       " Row(State='WI', Severity=1, count=1),\n",
       " Row(State='ME', Severity=1, count=1),\n",
       " Row(State='MS', Severity=1, count=1),\n",
       " Row(State='WV', Severity=1, count=1),\n",
       " Row(State='DC', Severity=1, count=1),\n",
       " Row(State='VT', Severity=1, count=1),\n",
       " Row(State='NM', Severity=1, count=1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_severity_freq = df.groupBy('State','Severity').count().orderBy('count',ascending=False).collect()\n",
    "state_severity_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    rdd = sc.parallelize(state_severity_freq)\n",
    "    pd_state_severity = rdd.toDF().toPandas()\n",
    "\n",
    "    # Plot data\n",
    "    fig,ax = plt.subplots(figsize=(16,10))\n",
    "    b = sns.barplot(x=\"State\", y=\"count\", hue=\"Severity\", data=pd_state_severity)\n",
    "    #b = sns.barplot(pd_state_severity['State', 'Severity'],pd_state_severity['count'])\n",
    "    b.axes.set_title(\"Severity distribution for each state\",fontsize=20)\n",
    "    b.set_xlabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.set_ylabel(\"State\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"severity_dist_class_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Weather_Condition='Clear', count=808171),\n",
       " Row(Weather_Condition='Mostly Cloudy', count=412528),\n",
       " Row(Weather_Condition='Overcast', count=382480),\n",
       " Row(Weather_Condition='Fair', count=335289),\n",
       " Row(Weather_Condition='Partly Cloudy', count=295439),\n",
       " Row(Weather_Condition='Scattered Clouds', count=204662),\n",
       " Row(Weather_Condition='Light Rain', count=141073),\n",
       " Row(Weather_Condition='Cloudy', count=115496),\n",
       " Row(Weather_Condition=None, count=65932),\n",
       " Row(Weather_Condition='Light Snow', count=42123),\n",
       " Row(Weather_Condition='Haze', count=34315),\n",
       " Row(Weather_Condition='Rain', count=32826),\n",
       " Row(Weather_Condition='Fog', count=22138),\n",
       " Row(Weather_Condition='Heavy Rain', count=12064),\n",
       " Row(Weather_Condition='Light Drizzle', count=10277),\n",
       " Row(Weather_Condition='Light Thunderstorms and Rain', count=4928),\n",
       " Row(Weather_Condition='Snow', count=4796),\n",
       " Row(Weather_Condition='Thunderstorm', count=4438),\n",
       " Row(Weather_Condition='Fair / Windy', count=3759),\n",
       " Row(Weather_Condition='Smoke', count=3602),\n",
       " Row(Weather_Condition='Heavy Thunderstorms and Rain', count=2483),\n",
       " Row(Weather_Condition='Patches of Fog', count=2386),\n",
       " Row(Weather_Condition='Thunderstorms and Rain', count=2215),\n",
       " Row(Weather_Condition='Mist', count=2204),\n",
       " Row(Weather_Condition='Thunder in the Vicinity', count=2177),\n",
       " Row(Weather_Condition='T-Storm', count=2161),\n",
       " Row(Weather_Condition='Light Freezing Rain', count=2132),\n",
       " Row(Weather_Condition='Cloudy / Windy', count=2097),\n",
       " Row(Weather_Condition='Drizzle', count=2044),\n",
       " Row(Weather_Condition='Mostly Cloudy / Windy', count=1987),\n",
       " Row(Weather_Condition='Light Rain with Thunder', count=1933),\n",
       " Row(Weather_Condition='Thunder', count=1661),\n",
       " Row(Weather_Condition='Partly Cloudy / Windy', count=1316),\n",
       " Row(Weather_Condition='Heavy T-Storm', count=1263),\n",
       " Row(Weather_Condition='Heavy Snow', count=1249),\n",
       " Row(Weather_Condition='Shallow Fog', count=1135),\n",
       " Row(Weather_Condition='Light Rain / Windy', count=1045),\n",
       " Row(Weather_Condition='Light Freezing Fog', count=1001),\n",
       " Row(Weather_Condition='Wintry Mix', count=799),\n",
       " Row(Weather_Condition='Light Freezing Drizzle', count=798),\n",
       " Row(Weather_Condition='Light Snow / Windy', count=453),\n",
       " Row(Weather_Condition='Rain / Windy', count=303),\n",
       " Row(Weather_Condition='Blowing Snow', count=268),\n",
       " Row(Weather_Condition='Showers in the Vicinity', count=267),\n",
       " Row(Weather_Condition='Light Ice Pellets', count=262),\n",
       " Row(Weather_Condition='Heavy Drizzle', count=258),\n",
       " Row(Weather_Condition='N/A Precipitation', count=201),\n",
       " Row(Weather_Condition='Heavy Rain / Windy', count=158),\n",
       " Row(Weather_Condition='Light Rain Showers', count=157),\n",
       " Row(Weather_Condition='Heavy T-Storm / Windy', count=146),\n",
       " Row(Weather_Condition='Widespread Dust', count=129),\n",
       " Row(Weather_Condition='T-Storm / Windy', count=128),\n",
       " Row(Weather_Condition='Rain Showers', count=123),\n",
       " Row(Weather_Condition='Ice Pellets', count=101),\n",
       " Row(Weather_Condition='Thunder / Windy', count=80),\n",
       " Row(Weather_Condition='Haze / Windy', count=66),\n",
       " Row(Weather_Condition='Drizzle and Fog', count=65),\n",
       " Row(Weather_Condition='Blowing Dust / Windy', count=64),\n",
       " Row(Weather_Condition='Fog / Windy', count=59),\n",
       " Row(Weather_Condition='Light Rain Shower', count=55),\n",
       " Row(Weather_Condition='Snow / Windy', count=50),\n",
       " Row(Weather_Condition='Blowing Dust', count=44),\n",
       " Row(Weather_Condition='Small Hail', count=30),\n",
       " Row(Weather_Condition='Light Drizzle / Windy', count=28),\n",
       " Row(Weather_Condition='Sand / Dust Whirlwinds', count=27),\n",
       " Row(Weather_Condition='Squalls', count=26),\n",
       " Row(Weather_Condition='Light Snow Showers', count=24),\n",
       " Row(Weather_Condition='Heavy Snow / Windy', count=23),\n",
       " Row(Weather_Condition='Volcanic Ash', count=22),\n",
       " Row(Weather_Condition='Light Thunderstorms and Snow', count=22),\n",
       " Row(Weather_Condition='Wintry Mix / Windy', count=20),\n",
       " Row(Weather_Condition='Funnel Cloud', count=19),\n",
       " Row(Weather_Condition='Sand', count=19),\n",
       " Row(Weather_Condition='Freezing Rain', count=17),\n",
       " Row(Weather_Condition='Partial Fog', count=10),\n",
       " Row(Weather_Condition='Light Haze', count=10),\n",
       " Row(Weather_Condition='Blowing Snow / Windy', count=10),\n",
       " Row(Weather_Condition='Light Snow with Thunder', count=9),\n",
       " Row(Weather_Condition='Light Snow and Sleet', count=9),\n",
       " Row(Weather_Condition='Snow and Sleet', count=9),\n",
       " Row(Weather_Condition='Snow and Sleet / Windy', count=9),\n",
       " Row(Weather_Condition='Heavy Thunderstorms with Small Hail', count=7),\n",
       " Row(Weather_Condition='Smoke / Windy', count=7),\n",
       " Row(Weather_Condition='Heavy Rain Showers', count=7),\n",
       " Row(Weather_Condition='Rain Shower', count=6),\n",
       " Row(Weather_Condition='Heavy Sleet', count=6),\n",
       " Row(Weather_Condition='Light Freezing Rain / Windy', count=6),\n",
       " Row(Weather_Condition='Light Snow Grains', count=6),\n",
       " Row(Weather_Condition='Heavy Snow with Thunder', count=6),\n",
       " Row(Weather_Condition='Low Drifting Snow', count=5),\n",
       " Row(Weather_Condition='Heavy Thunderstorms and Snow', count=5),\n",
       " Row(Weather_Condition='Squalls / Windy', count=5),\n",
       " Row(Weather_Condition='Light Sleet', count=4),\n",
       " Row(Weather_Condition='Heavy Ice Pellets', count=4),\n",
       " Row(Weather_Condition='Snow Grains', count=4),\n",
       " Row(Weather_Condition='Heavy Blowing Snow', count=4),\n",
       " Row(Weather_Condition='Light Fog', count=4),\n",
       " Row(Weather_Condition='Drizzle / Windy', count=4),\n",
       " Row(Weather_Condition='Light Snow and Sleet / Windy', count=4),\n",
       " Row(Weather_Condition='Sleet', count=3),\n",
       " Row(Weather_Condition='Light Blowing Snow', count=3),\n",
       " Row(Weather_Condition='Tornado', count=3),\n",
       " Row(Weather_Condition='Light Hail', count=3),\n",
       " Row(Weather_Condition='Light Thunderstorm', count=3),\n",
       " Row(Weather_Condition='Thunderstorms and Snow', count=3),\n",
       " Row(Weather_Condition='Sand / Dust Whirlwinds / Windy', count=2),\n",
       " Row(Weather_Condition='Snow Showers', count=2),\n",
       " Row(Weather_Condition='Heavy Freezing Drizzle', count=2),\n",
       " Row(Weather_Condition='Heavy Freezing Rain', count=2),\n",
       " Row(Weather_Condition='Hail', count=2),\n",
       " Row(Weather_Condition='Light Rain Shower / Windy', count=1),\n",
       " Row(Weather_Condition='Freezing Rain / Windy', count=1),\n",
       " Row(Weather_Condition='Heavy Smoke', count=1),\n",
       " Row(Weather_Condition='Widespread Dust / Windy', count=1),\n",
       " Row(Weather_Condition='Thunder and Hail / Windy', count=1),\n",
       " Row(Weather_Condition='Partial Fog / Windy', count=1),\n",
       " Row(Weather_Condition='Dust Whirls', count=1),\n",
       " Row(Weather_Condition='Snow and Thunder', count=1),\n",
       " Row(Weather_Condition='Thunder / Wintry Mix / Windy', count=1),\n",
       " Row(Weather_Condition='Blowing Sand', count=1),\n",
       " Row(Weather_Condition='Light Snow Shower', count=1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_freq = df.groupBy('Weather_Condition').count().orderBy('count',ascending=False).collect()\n",
    "weather_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Weather_Condition='Clear', count=808171), Row(Weather_Condition='Mostly Cloudy', count=412528), Row(Weather_Condition='Overcast', count=382480), Row(Weather_Condition='Fair', count=335289), Row(Weather_Condition='Partly Cloudy', count=295439), Row(Weather_Condition='Scattered Clouds', count=204662), Row(Weather_Condition='Light Rain', count=141073), Row(Weather_Condition='Cloudy', count=115496), Row(Weather_Condition=None, count=65932), Row(Weather_Condition='Light Snow', count=42123), Row(Weather_Condition='Haze', count=34315), Row(Weather_Condition='Rain', count=32826), Row(Weather_Condition='Fog', count=22138), Row(Weather_Condition='Heavy Rain', count=12064), Row(Weather_Condition='Light Drizzle', count=10277), Row(Weather_Condition='Light Thunderstorms and Rain', count=4928), Row(Weather_Condition='Snow', count=4796), Row(Weather_Condition='Thunderstorm', count=4438), Row(Weather_Condition='Fair / Windy', count=3759), Row(Weather_Condition='Smoke', count=3602)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = int(df.count()*0.001) # Limit the plot to ignore conditions below an limit\n",
    "\n",
    "rdd = sc.parallelize(weather_freq)\n",
    "rdd_filtered = rdd.filter(lambda x: x['count'] > n)\n",
    "print(rdd_filtered.collect())\n",
    "\n",
    "if enabled == True:\n",
    "    fig, ax=plt.subplots(figsize=(16,25))\n",
    "    pd_weather = rdd_filtered.toDF().toPandas()\n",
    "\n",
    "    b = sns.barplot(pd_weather['count'][:],pd_weather['Weather_Condition'][:], color=\"blue\")\n",
    "\n",
    "    b.axes.set_title(\"Weather Condition for accidents above 1% of total set\",fontsize=20)\n",
    "    b.set_xlabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.set_ylabel(\"Weather_Condition\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"weather_cond_dist\")\n",
    "    logger.write2file(\"Weather condition distribution\", str(pd_weather))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time when accidents occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Start_Time=3, count=251893),\n",
       " Row(Start_Time=2, count=227588),\n",
       " Row(Start_Time=4, count=210291),\n",
       " Row(Start_Time=11, count=185877),\n",
       " Row(Start_Time=12, count=185042),\n",
       " Row(Start_Time=10, count=181391),\n",
       " Row(Start_Time=1, count=168954),\n",
       " Row(Start_Time=9, count=164708),\n",
       " Row(Start_Time=5, count=162704),\n",
       " Row(Start_Time=13, count=155228),\n",
       " Row(Start_Time=6, count=154872),\n",
       " Row(Start_Time=7, count=154414),\n",
       " Row(Start_Time=8, count=153547),\n",
       " Row(Start_Time=0, count=116025),\n",
       " Row(Start_Time=14, count=105595),\n",
       " Row(Start_Time=15, count=76873),\n",
       " Row(Start_Time=23, count=73396),\n",
       " Row(Start_Time=16, count=57092),\n",
       " Row(Start_Time=22, count=43593),\n",
       " Row(Start_Time=17, count=42607),\n",
       " Row(Start_Time=18, count=29586),\n",
       " Row(Start_Time=21, count=27565),\n",
       " Row(Start_Time=20, count=21421),\n",
       " Row(Start_Time=19, count=20910),\n",
       " Row(Start_Time=None, count=3163)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time = df.selectExpr(\"hour(to_timestamp(from_utc_timestamp(Start_Time, Timezone), 'yyyy-MM-dd HH:mm:ss')) as Start_Time\")\n",
    "time_freq = df_time.groupBy('Start_Time').count().orderBy('count',ascending=False).collect()\n",
    "time_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    dd = sc.parallelize(time_freq)\n",
    "    pd_time = rdd.toDF().toPandas()\n",
    "\n",
    "    # Plot data\n",
    "    fig,ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "    b = sns.barplot(pd_time['Start_Time'],pd_time['count'], color='blue')\n",
    "    b.axes.set_title(\"Daytime for accidents\",fontsize=20)\n",
    "    b.set_xlabel(\"Time (Hours)\",fontsize=15)\n",
    "    b.set_ylabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"accident_hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development of accidents on Month basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Start_Time=10, count=324135),\n",
       " Row(Start_Time=12, count=299258),\n",
       " Row(Start_Time=11, count=298801),\n",
       " Row(Start_Time=9, count=292194),\n",
       " Row(Start_Time=8, count=288566),\n",
       " Row(Start_Time=7, count=222828),\n",
       " Row(Start_Time=4, count=211588),\n",
       " Row(Start_Time=6, count=209902),\n",
       " Row(Start_Time=1, count=209776),\n",
       " Row(Start_Time=5, count=208812),\n",
       " Row(Start_Time=3, count=206805),\n",
       " Row(Start_Time=2, count=198507),\n",
       " Row(Start_Time=None, count=3163)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time = df.selectExpr(\"month(to_timestamp(from_utc_timestamp(Start_Time, Timezone), 'yyyy-MM-dd HH:mm:ss')) as Start_Time\")\n",
    "time_freq = df_time.groupBy('Start_Time').count().orderBy('count',ascending=False).collect()\n",
    "time_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    rdd = sc.parallelize(time_freq)\n",
    "    pd_time = rdd.toDF().toPandas()\n",
    "\n",
    "    # Plot data\n",
    "    fig,ax = plt.subplots(figsize=(16,10))\n",
    "\n",
    "    b = sns.barplot(pd_time['Start_Time'],pd_time['count'], color='blue')\n",
    "    b.axes.set_title(\"Montly distribution for accidents\",fontsize=20)\n",
    "    b.set_xlabel(\"Time (Month)\",fontsize=15)\n",
    "    b.set_ylabel(\"Number of Accidents\",fontsize=15)\n",
    "    b.tick_params(labelsize=10)\n",
    "\n",
    "    logger.saveImage(b,\"accudents_months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enabled == True:\n",
    "    b = sns.jointplot(x=df.select(collect_list('Start_Lat')).first()[0],y=df.select(collect_list('Start_Lng')).first()[0],height=10)\n",
    "\n",
    "    b.set_axis_labels('Start_Lat','Start_Lng')\n",
    "    b.fig.suptitle(\"Map distribution of accidents\")\n",
    "    logger.saveImage(b,\"accident_map_dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.write2file(\"New Analysis created!\", \\\n",
    "               \"Model finished: Yes\" + \\\n",
    "               \"\\nFolder name: \" + logger.timeSignature + \\\n",
    "               \"\\nState: \"+ \"Not defined\" + \\\n",
    "               \"\\nLogs directory: \" + logger.logs_dir +  \\\n",
    "               \"\\nFile: \" + file + \\\n",
    "               \"\\nNote: \" + model_Note, \\\n",
    "               logs_dir=model_indexing_dir \\\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
