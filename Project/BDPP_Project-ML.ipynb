{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import ibmos2spark\n",
    "# @hidden_cell\n",
    "credentials = {\n",
    "    'endpoint': 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'service_id': 'iam-ServiceId-1d71bac5-a341-449f-9ca7-b29de95e771a',\n",
    "    'iam_service_endpoint': 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'api_key': 'ejujKveBRS3Bk7l3pzjemEQDhTSaOKmqCg6x6osXWkx4'\n",
    "}\n",
    "\n",
    "configuration_name = 'os_2d970470a6354234a1716fe9f4db519b_configs'\n",
    "cos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option('header', 'true')\\\n",
    "  .load(cos.url('US_Accidents_Dec19.csv', 'bdppproject-donotdelete-pr-nejualq57kuqe4'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "try:\n",
    "    spark.close()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "try:\n",
    "    conf = SparkConf().setAppName('Spark Project')\n",
    "    sc = SparkContext(conf=conf)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#.config(\"spark.some.config.option\", \"some-value\") \\\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
    "#spark = SparkSession \\\n",
    "#    .builder \\\n",
    "#    .appName(\"Spark Project\") \\\n",
    "#    .config(\"spark.executor.memory\", '5g') \\\n",
    "#    .config(\"spark.driver.memory\", '5g') \\\n",
    "#    .getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Project\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"70g\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",True) \\\n",
    "     .config(\"spark.memory.offHeap.size\",\"16g\")  \\\n",
    "    .config(\"spark.yarn.executor.memoryOverhead\",200) \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.default.parallelism\", \"6\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.load(\"data/US_Accidents_Dec19.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Damon:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Spark Project>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.port', '54834'),\n",
       " ('spark.app.id', 'local-1588170628522'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.driver.host', 'Damon'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.name', 'Spark Project'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, count, col, isnan, countDistinct,from_unixtime,from_utc_timestamp, unix_timestamp,split, to_timestamp, hour, month, lit,collect_list\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Due to problem in spark 3.0.0\n",
    "spark.conf.set(\"spark.sql.legacy.utcTimestampFunc.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_Time', 'Street', 'Side', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code', 'Weather_Timestamp', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
      "['TMC', 'Start_Lat', 'Start_Lng', 'Distance(mi)', 'Number', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n"
     ]
    }
   ],
   "source": [
    "# Define data information\n",
    "\n",
    "# Choose directory\n",
    "#projDir = \"C:\\Users\\fredr\\Documents\\github-projects\\BDPP-Labs\\Project\\Models\"\n",
    "\n",
    "\n",
    "# Numerical values\n",
    "\n",
    "colLabel = [\"Severity\"]\n",
    "\n",
    "colRem = ['ID', \n",
    "          'Source',\n",
    "          'End_Time',\n",
    "          'End_Lat',\n",
    "          'End_Lng',\n",
    "          'Description',\n",
    "        ]\n",
    "\n",
    "# Dropping data that cant help during model\n",
    "df = df.drop(*colRem)\n",
    "\n",
    "# Convert boolean to string since PCA cant handle boolean which should be a class\n",
    "df = df.select(*[col(c[0]).cast(\"string\").alias(c[0]) if c[1] == 'boolean' else col(c[0]).alias(c[0]) for c in df.dtypes])\n",
    "\n",
    "#renamedHousing.select([count(when(col(c).isNull(), c)).alias(c) for c in colNum]).show()\n",
    "rdd = sc.parallelize(df.dtypes)\n",
    "\n",
    "colCat = rdd.map(lambda i: i[0] if (i[1]=='string' or i[1]=='boolean' and i[0]) else None).filter(lambda i: i != None).collect()\n",
    "colNum = rdd.map(lambda i: i[0] if (i[1]=='double' and i[0]) else None).filter(lambda i: i != None).collect()\n",
    "\n",
    "print(colCat)\n",
    "print(colNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse single city\n",
    "This could be CA since it stands for a little less than 50% of the total set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.State == \"CA\") # Lowers the dataset quite a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify time\n",
    "Convert the timestamp into a numeric value and then into a string so that the time of day and month can be categorised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------------------+---------+-----------+------------+------+-----------+----+-------+------+-----+-------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------+-----------+------------+-------------+\n",
      "|  TMC|Severity|         Start_Time|Start_Lat|  Start_Lng|Distance(mi)|Number|     Street|Side|   City|County|State|Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|Start_Hour|Start_Month|Weather_Hour|Weather_Month|\n",
      "+-----+--------+-------------------+---------+-----------+------------+------+-----------+----+-------+------+-----+-------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------+-----------+------------+-------------+\n",
      "|201.0|       3|2016-06-21 10:34:40|  38.0853|-122.233017|         0.0|  null|Magazine St|   R|Vallejo|Solano|   CA|  94591|     US|US/Pacific|        KAPC|2016-06-21 10:54:00|          75.0|         null|       48.0|        30.0|          10.0|      Variable|            5.8|             null|            Clear|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|           Day|           Day|              Day|                  Day|         3|          6|           3|            6|\n",
      "+-----+--------+-------------------+---------+-----------+------------+------+-----------+----+-------+------+-----+-------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------+-----------+------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert to int then cast to string\n",
    "\n",
    "df = df.withColumn('Start_Hour', hour(to_timestamp(from_utc_timestamp(df['Start_Time'], df['Timezone']).cast('string'), 'yyyy-MM-dd HH:mm:ss')))\n",
    "df = df.withColumn('Start_Month', month(to_timestamp(from_utc_timestamp(df['Start_Time'], df['Timezone']).cast('string'), 'yyyy-MM-dd HH:mm:ss')))\n",
    "\n",
    "df = df.withColumn('Weather_Hour', hour(to_timestamp(from_utc_timestamp(df['Weather_Timestamp'], df['Timezone']).cast('string'), 'yyyy-MM-dd HH:mm:ss')))\n",
    "df = df.withColumn('Weather_Month', month(to_timestamp(from_utc_timestamp(df['Weather_Timestamp'], df['Timezone']).cast('string'), 'yyyy-MM-dd HH:mm:ss')))\n",
    "\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast data\n",
    "Cast all the datacolumns into correct format so they will be sorted to numerical or categorical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from string to integer values\n",
    "# TODO: Does not work since data contains Nan/Null?\n",
    "df = df.select(\n",
    "        col('TMC').cast('string'),\n",
    "        col('Severity').cast('int'),\n",
    "        #col('Start_Time').cast('int'),\n",
    "        col('Start_Hour').cast('string'),\n",
    "        col('Start_Month').cast('string'),\n",
    "        col('Weather_Hour').cast('string'),\n",
    "        col('Weather_Month').cast('string'),\n",
    "        #col('Start_Lat').cast('string'),\n",
    "        #col('Start_Lng').cast('string'),\n",
    "        col('Distance(mi)').cast('double'),\n",
    "        col('Street').cast('string'),       # Remove eventually?\n",
    "        col('Side').cast('string'),         # Remove eventually?\n",
    "        col('City').cast('string'),         # Remove eventually?\n",
    "        col('State').cast('string'),        # Remove eventually?\n",
    "        #col('Zipcode').cast('string'),      # Remove eventually?\n",
    "        #col('Country').cast('string'),      # Remove eventually?\n",
    "        #col('Airport_Code').cast('string'), # Remove eventually?\n",
    "      #  col('Weather_Timestamp').cast('int'),\n",
    "        col('Temperature(F)').cast('double'),\n",
    "        col('Wind_Chill(F)').cast('double'),\n",
    "        col('Humidity(%)').cast('double'),\n",
    "        col('Pressure(in)').cast('double'),\n",
    "        col('Visibility(mi)').cast('double'),\n",
    "        col('Wind_Direction').cast('string'),\n",
    "        col('Wind_Speed(mph)').cast('double'),\n",
    "        col('Weather_Condition').cast('string'),\n",
    "        col('Amenity').cast('string'),\n",
    "        col('Bump').cast('string'),\n",
    "        col('Crossing').cast('string'),\n",
    "        col('Give_Way').cast('string'),\n",
    "        col('Junction').cast('string'),\n",
    "        col('No_Exit').cast('string'),\n",
    "        col('Railway').cast('string'),\n",
    "        col('Roundabout').cast('string'),\n",
    "        col('Station').cast('string'),\n",
    "        col('Stop').cast('string'),\n",
    "        col('Traffic_Calming').cast('string'),\n",
    "        col('Traffic_Signal').cast('string'),\n",
    "        col('Turning_Loop').cast('string'),\n",
    "        col('Sunrise_Sunset').cast('string'),\n",
    "        col('Civil_Twilight').cast('string'),\n",
    "        col('Nautical_Twilight').cast('string'),\n",
    "        col('Astronomical_Twilight').cast('string')\n",
    "    ) \n",
    "\n",
    "# Since the last check can be unorganised we recreate a new list that contains all data\n",
    "colLabel = [\"Severity\"]\n",
    "\n",
    "rdd = sc.parallelize(df.dtypes)\n",
    "colCat = rdd.map(lambda i: i[0] if (i[1]=='string' or i[1]=='boolean' and i[0] not in colLabel) else None).filter(lambda i: i != None).collect()\n",
    "colNum = rdd.map(lambda i: i[0] if (i[1]=='double' and i[0] not in colLabel) else None).filter(lambda i: i != None).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Severity']\n",
      "['TMC', 'Start_Hour', 'Start_Month', 'Weather_Hour', 'Weather_Month', 'Street', 'Side', 'City', 'State', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight']\n",
      "['Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)']\n"
     ]
    }
   ],
   "source": [
    "print(colLabel)\n",
    "print(colCat)\n",
    "print(colNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove data containing NaN (Drop)\n",
    "Since NaN and Null occurs we drop these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89563"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()\n",
    "df = df.na.drop()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recheck the missing values\n",
    "Check so that the output contains 0 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TMC=0, Severity=0, Start_Hour=0, Start_Month=0, Weather_Hour=0, Weather_Month=0, Distance(mi)=0, Street=0, Side=0, City=0, State=0, Temperature(F)=0, Wind_Chill(F)=0, Humidity(%)=0, Pressure(in)=0, Visibility(mi)=0, Wind_Direction=0, Wind_Speed(mph)=0, Weather_Condition=0, Amenity=0, Bump=0, Crossing=0, Give_Way=0, Junction=0, No_Exit=0, Railway=0, Roundabout=0, Station=0, Stop=0, Traffic_Calming=0, Traffic_Signal=0, Turning_Loop=0, Sunrise_Sunset=0, Civil_Twilight=0, Nautical_Twilight=0, Astronomical_Twilight=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missingVals_cols = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "# Missing value in each column\n",
    "df_missingVals_cols.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove data with occurance less than 1%\n",
    "Based on information from analysis. With further analysis lower procentage can be used to find better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   Weather_Condition|count|\n",
      "+--------------------+-----+\n",
      "|                Fair|42320|\n",
      "|              Cloudy|13231|\n",
      "|       Partly Cloudy| 9610|\n",
      "|       Mostly Cloudy| 8372|\n",
      "|               Clear| 5317|\n",
      "|          Light Rain| 2626|\n",
      "|                Haze| 2381|\n",
      "|                 Fog| 1351|\n",
      "|            Overcast| 1128|\n",
      "|                Rain|  833|\n",
      "|        Fair / Windy|  523|\n",
      "|    Scattered Clouds|  463|\n",
      "|          Heavy Rain|  283|\n",
      "|               Smoke|  189|\n",
      "|          Light Snow|  125|\n",
      "|Partly Cloudy / W...|  110|\n",
      "|Mostly Cloudy / W...|   93|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89563"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_freq = df.groupBy('Weather_Condition').count().orderBy('count',ascending=False)\n",
    "\n",
    "n = int(df.count()*0.001) # Limit the plot to ignore conditions below an limit\n",
    "\n",
    "df_filtered = weather_freq.filter(weather_freq['count'] > n)\n",
    "df_filtered.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fair', 'Cloudy', 'Partly Cloudy', 'Mostly Cloudy', 'Clear', 'Light Rain', 'Haze', 'Fog', 'Overcast', 'Rain', 'Fair / Windy', 'Scattered Clouds', 'Heavy Rain', 'Smoke', 'Light Snow', 'Partly Cloudy / Windy', 'Mostly Cloudy / Windy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88955"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_conditions = df_filtered.select(\"Weather_Condition\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "print(filtered_conditions)\n",
    "\n",
    "test1 = df.filter(df['Weather_Condition'].isin(*filtered_conditions))\n",
    "\n",
    "df = test1 # Adding the filtered data to dataframe (Hopefully we lose less than n% of the data) but reduce the dimension of feature vector\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles function\n",
    "Alternative solution to get position (Work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndscretizer_Lat = QuantileDiscretizer(numBuckets=50, inputCol=\"Start_Lat\", outputCol=\"Start_Lat\")\\ndscretizer_Lng = QuantileDiscretizer(numBuckets=50, inputCol=\"Start_Lng\", outputCol=\"Start_Lng\")\\n\\n# Convert into categorical values (two blocks)\\nquant_Lat_model = quantiles_Lat.fit(df_features)\\nquant_Lng_model = quantiles_Lng.fit(df_features) \\n\\nquanted_Lat = quant_Lat_model.transform(df_features)\\nquanted_Lng = quant_Lng_model.transform(df_features)\\n\\n# Into categorical values\\nstringIndexer = StringIndexer(inputCol=[\"Start_Lat\",\"Start_Lng\"], outputCol=[\"Start_Lat\",\"Start_Lng\"] + \"_num\")\\nindexer_model = stringIndexer.fit(df_features) # Change into Quanted_Lat, Quanted_Lng\\nindexed = indexer_model.transform(df_features)\\n\\n# One-hot \\nencoder = OneHotEncoder(inputCols=[\"Start_Lat_num\",\"Start_Lng_num\"], outputCols=[s + \"_vec\" for s in colCat])\\n\\nencoded = encoder.fit(indexed)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove City, Country, State, Zipcode, Airport_Code\n",
    "# In order to reduce dimensionality a kernel function will be applied upon the Start_Lat and Start_Lng then fused in order to create a new set of data\n",
    "# Start_Lat\n",
    "# Start_Lng\n",
    "\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\"\"\"\n",
    "dscretizer_Lat = QuantileDiscretizer(numBuckets=50, inputCol=\"Start_Lat\", outputCol=\"Start_Lat\")\n",
    "dscretizer_Lng = QuantileDiscretizer(numBuckets=50, inputCol=\"Start_Lng\", outputCol=\"Start_Lng\")\n",
    "\n",
    "# Convert into categorical values (two blocks)\n",
    "quant_Lat_model = quantiles_Lat.fit(df_features)\n",
    "quant_Lng_model = quantiles_Lng.fit(df_features) \n",
    "\n",
    "quanted_Lat = quant_Lat_model.transform(df_features)\n",
    "quanted_Lng = quant_Lng_model.transform(df_features)\n",
    "\n",
    "# Into categorical values\n",
    "stringIndexer = StringIndexer(inputCol=[\"Start_Lat\",\"Start_Lng\"], outputCol=[\"Start_Lat\",\"Start_Lng\"] + \"_num\")\n",
    "indexer_model = stringIndexer.fit(df_features) # Change into Quanted_Lat, Quanted_Lng\n",
    "indexed = indexer_model.transform(df_features)\n",
    "\n",
    "# One-hot \n",
    "encoder = OneHotEncoder(inputCols=[\"Start_Lat_num\",\"Start_Lng_num\"], outputCols=[s + \"_vec\" for s in colCat])\n",
    "\n",
    "encoded = encoder.fit(indexed)\n",
    "\"\"\"\n",
    "\n",
    "# Do multiplication into a final feature vector (Kernel trick)\n",
    "\n",
    "# Remove City, Country, State, Zipcode, Airport_Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer_c5669186edb7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probobly a bad Idea but why not?\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "#imputer = Imputer(inputCols=['Wind_Chill(F)', 'Wind_Speed(mph)'], outputCols=['Wind_Chill(F)', 'Wind_Speed(mph)'])\n",
    "imputer = Imputer(inputCols=colNum, outputCols=colNum)\n",
    "imputer.setStrategy(\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler_b06111df4d93"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "#Create a vector\n",
    "num_assembler = VectorAssembler(inputCols=colNum, outputCol=\"num_features\",handleInvalid=\"keep\")\n",
    "scaler = StandardScaler(inputCol=\"num_features\", withMean=True, withStd=True, outputCol=\"scaledFeatures\")\n",
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StringIndexer_664a66fc11b3, StringIndexer_f21596f5353b, StringIndexer_2b3aebc0731a, StringIndexer_8f95b76ef58b, StringIndexer_d2165564a0d8, StringIndexer_f4295b6ecee4, StringIndexer_4d0abdcfadef, StringIndexer_ab8365ebad81, StringIndexer_94cae7a421fb, StringIndexer_a92712581716, StringIndexer_83ab83f9cbe3, StringIndexer_6e1faf10d558, StringIndexer_2258dd4edce5, StringIndexer_1a96a7b88f31, StringIndexer_a70126bec3e8, StringIndexer_d7249e6673ee, StringIndexer_fc3a744b85da, StringIndexer_af251ec28c35, StringIndexer_b7025f849367, StringIndexer_d6d056bc5704, StringIndexer_d8466531547f, StringIndexer_d040642f09ae, StringIndexer_2cc7b1187f24, StringIndexer_bc605b89a4a6, StringIndexer_3bf9b61538bb, StringIndexer_9ba103505f2b, StringIndexer_f10ad26f175e, StringIndexer_d7d2be2df76d]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "#colCat\n",
    "#col_assembler = VectorAssembler(inputCols=colCat, outputCol=\"cat_features\",handleInvalid=\"keep\")\n",
    "#indexers = StringIndexer(inputCol=\"cat_features\", outputCol=\"indexedFeatures\",handleInvalid=\"keep\")\n",
    "\n",
    "indexers = [StringIndexer(inputCol = c, outputCol = c +'_IDX', handleInvalid='keep') for c in colCat]\n",
    "print(indexers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "#from pyspark.ml import Pipeline\n",
    "#pipeline = Pipeline(stages=indexers)\n",
    "#df_indexers = pipeline.fit(df).transform(df)\n",
    "\n",
    "#col_assembler = VectorAssembler(inputCols=[c +'_IDX' for c in colCat], outputCol=\"features\",handleInvalid=\"keep\")\n",
    "#data = col_assembler.transform(df_indexers)\n",
    "#df_features.withColumn('features', col(col_assembler.transform(df_indexers)))\n",
    "#df_indexers.select([c +'_IDX' for c in colCat]).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder_34ed03483f16\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder \n",
    "\n",
    "#ohe = OneHotEncoder()\n",
    "#ohe.setInputCols([c + \"_IDX\" for c in colCat])\n",
    "#ohe.setOutputCols([c + \"_IDX_vec\" for c in colCat])\n",
    "\n",
    "#col_assembler = VectorAssembler(inputCols=[c + \"_IDX\" for c in colCat], outputCol=\"col_features\",handleInvalid=\"keep\")\n",
    "encoder = OneHotEncoder(inputCols=[c + \"_IDX\" for c in colCat], outputCols=[c + \"_IDX_vec\" for c in colCat],handleInvalid=\"keep\")\n",
    "#encoder = OneHotEncoder(inputCol=\"col_features\", outputCol=\"col_features_vec\",handleInvalid=\"keep\")\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "#from pyspark.ml import Pipeline \n",
    "#pipeline = Pipeline(stages=[*indexers,*encoder])\n",
    "#df_indexers = pipeline.fit(df).transform(df)\n",
    "#df_indexers.select([c +'_IDX_vec' for c in colCat]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "|  TMC|Severity|Start_Hour|Start_Month|Weather_Hour|Weather_Month|Distance(mi)|    Street|Side|        City|State|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|\n",
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "|201.0|       2|         8|         11|           8|           11|        0.01|Garden Cir|   R|Cameron Park|   CA|          44.6|         41.4|       87.0|       30.06|          10.0|         North|            5.8|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|           Day|           Day|              Day|                  Day|\n",
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count categorical values\n",
    "Confirm the amount of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TMC': 19,\n",
       " 'Start_Hour': 24,\n",
       " 'Start_Month': 12,\n",
       " 'Weather_Hour': 24,\n",
       " 'Weather_Month': 12,\n",
       " 'Street': 9096,\n",
       " 'Side': 2,\n",
       " 'City': 967,\n",
       " 'State': 1,\n",
       " 'Wind_Direction': 23,\n",
       " 'Weather_Condition': 17,\n",
       " 'Amenity': 2,\n",
       " 'Bump': 2,\n",
       " 'Crossing': 2,\n",
       " 'Give_Way': 2,\n",
       " 'Junction': 2,\n",
       " 'No_Exit': 2,\n",
       " 'Railway': 2,\n",
       " 'Roundabout': 2,\n",
       " 'Station': 2,\n",
       " 'Stop': 2,\n",
       " 'Traffic_Calming': 2,\n",
       " 'Traffic_Signal': 2,\n",
       " 'Turning_Loop': 1,\n",
       " 'Sunrise_Sunset': 2,\n",
       " 'Civil_Twilight': 2,\n",
       " 'Nautical_Twilight': 2,\n",
       " 'Astronomical_Twilight': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(*(countDistinct(col(c)).alias(c) for c in colCat)).collect()[0].asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical values\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "numPipeline = Pipeline(stages=[imputer, num_assembler, scaler])\n",
    "catPipeline = Pipeline(stages=[*indexers, encoder])\n",
    "\n",
    "#.select(\"scaledFeatures\", *[c +'_IDX_vec' for c in colCat])\n",
    "pipeline = Pipeline(stages=[numPipeline, catPipeline])\n",
    "preprocessed_df = pipeline.fit(df).transform(df)\n",
    "#print(\"Saving model\")\n",
    "#preprocessed_df.save(projDir + \"\\pipeline\")\n",
    "#print(\"Saved complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_df = preprocessed_df.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catPipeline.fit(df).transform(df).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+-------------------+--------------------+---------------------+-------------------+-------------+-----------------+-------------+----------------------+-------------------------+---------------+-------------+----------------+----------------+----------------+---------------+---------------+------------------+---------------+-------------+-----------------------+----------------------+--------------------+----------------------+----------------------+-------------------------+-----------------------------+\n",
      "|scaledFeatures                                                                                                                                |TMC_IDX_vec   |Start_Hour_IDX_vec|Start_Month_IDX_vec|Weather_Hour_IDX_vec|Weather_Month_IDX_vec|Street_IDX_vec     |Side_IDX_vec |City_IDX_vec     |State_IDX_vec|Wind_Direction_IDX_vec|Weather_Condition_IDX_vec|Amenity_IDX_vec|Bump_IDX_vec |Crossing_IDX_vec|Give_Way_IDX_vec|Junction_IDX_vec|No_Exit_IDX_vec|Railway_IDX_vec|Roundabout_IDX_vec|Station_IDX_vec|Stop_IDX_vec |Traffic_Calming_IDX_vec|Traffic_Signal_IDX_vec|Turning_Loop_IDX_vec|Sunrise_Sunset_IDX_vec|Civil_Twilight_IDX_vec|Nautical_Twilight_IDX_vec|Astronomical_Twilight_IDX_vec|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+-------------------+--------------------+---------------------+-------------------+-------------+-----------------+-------------+----------------------+-------------------------+---------------+-------------+----------------+----------------+----------------+---------------+---------------+------------------+---------------+-------------+-----------------------+----------------------+--------------------+----------------------+----------------------+-------------------------+-----------------------------+\n",
      "|[-0.11543774529750594,-1.361211368226371,-1.4702415889663176,1.0647461213830427,0.7230555107167154,0.3632274174204553,-0.006063465922271304]  |(20,[0],[1.0])|(25,[7],[1.0])    |(13,[1],[1.0])     |(25,[7],[1.0])      |(13,[1],[1.0])       |(9097,[6156],[1.0])|(3,[0],[1.0])|(968,[466],[1.0])|(2,[0],[1.0])|(24,[19],[1.0])       |(18,[3],[1.0])           |(3,[0],[1.0])  |(3,[0],[1.0])|(3,[0],[1.0])   |(3,[0],[1.0])   |(3,[0],[1.0])   |(3,[0],[1.0])  |(3,[0],[1.0])  |(3,[0],[1.0])     |(3,[0],[1.0])  |(3,[0],[1.0])|(3,[0],[1.0])          |(3,[0],[1.0])         |(2,[0],[1.0])       |(3,[0],[1.0])         |(3,[0],[1.0])         |(3,[0],[1.0])            |(3,[0],[1.0])                |\n",
      "|[-0.11543774529750594,-1.4934208165488596,-1.491003757158492,1.3253799063906717,0.7230555107167154,-0.052638836136874735,-0.46932344783574076]|(20,[1],[1.0])|(25,[4],[1.0])    |(13,[1],[1.0])     |(25,[5],[1.0])      |(13,[1],[1.0])       |(9097,[1000],[1.0])|(3,[1],[1.0])|(968,[135],[1.0])|(2,[0],[1.0])|(24,[19],[1.0])       |(18,[8],[1.0])           |(3,[0],[1.0])  |(3,[0],[1.0])|(3,[0],[1.0])   |(3,[0],[1.0])   |(3,[0],[1.0])   |(3,[0],[1.0])  |(3,[0],[1.0])  |(3,[0],[1.0])     |(3,[0],[1.0])  |(3,[0],[1.0])|(3,[0],[1.0])          |(3,[0],[1.0])         |(2,[0],[1.0])       |(3,[1],[1.0])         |(3,[1],[1.0])         |(3,[1],[1.0])            |(3,[1],[1.0])                |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+------------------+-------------------+--------------------+---------------------+-------------------+-------------+-----------------+-------------+----------------------+-------------------------+---------------+-------------+----------------+----------------+----------------+---------------+---------------+------------------+---------------+-------------+-----------------------+----------------------+--------------------+----------------------+----------------------+-------------------------+-----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df.select(\"scaledFeatures\",*[c + \"_IDX_vec\" for c in colCat]).show(2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+--------------------+--------------------+-------+--------------+---------------+----------------+-----------------+----------+--------+--------+---------+------------------+---------------------+-----------+--------+------------+------------+------------+-----------+-----------+--------------+-----------+--------+-------------------+------------------+----------------+------------------+------------------+---------------------+-------------------------+--------------------+----------------+-----------------------------+----------------------+-------------------------+-----------------------+---------------+----------------------+-------------+-------------------+------------------+-------------+----------------+-------------------+----------------------+------------------+---------------+---------------+---------------+----------------------+-------------+--------------------+---------------------+-------------+-----------------+----------------+-------------------------+--------------+--------------------+\n",
      "|  TMC|Severity|Start_Hour|Start_Month|Weather_Hour|Weather_Month|Distance(mi)|    Street|Side|        City|State|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|        num_features|      scaledFeatures|TMC_IDX|Start_Hour_IDX|Start_Month_IDX|Weather_Hour_IDX|Weather_Month_IDX|Street_IDX|Side_IDX|City_IDX|State_IDX|Wind_Direction_IDX|Weather_Condition_IDX|Amenity_IDX|Bump_IDX|Crossing_IDX|Give_Way_IDX|Junction_IDX|No_Exit_IDX|Railway_IDX|Roundabout_IDX|Station_IDX|Stop_IDX|Traffic_Calming_IDX|Traffic_Signal_IDX|Turning_Loop_IDX|Sunrise_Sunset_IDX|Civil_Twilight_IDX|Nautical_Twilight_IDX|Astronomical_Twilight_IDX|Turning_Loop_IDX_vec|Give_Way_IDX_vec|Astronomical_Twilight_IDX_vec|Wind_Direction_IDX_vec|Weather_Condition_IDX_vec|Traffic_Calming_IDX_vec|Railway_IDX_vec|Traffic_Signal_IDX_vec| Bump_IDX_vec|     Street_IDX_vec|Start_Hour_IDX_vec| Side_IDX_vec|Junction_IDX_vec|Start_Month_IDX_vec|Sunrise_Sunset_IDX_vec|Roundabout_IDX_vec|Station_IDX_vec|No_Exit_IDX_vec|Amenity_IDX_vec|Civil_Twilight_IDX_vec| Stop_IDX_vec|Weather_Hour_IDX_vec|Weather_Month_IDX_vec|State_IDX_vec|     City_IDX_vec|Crossing_IDX_vec|Nautical_Twilight_IDX_vec|   TMC_IDX_vec|      final_features|\n",
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+--------------------+--------------------+-------+--------------+---------------+----------------+-----------------+----------+--------+--------+---------+------------------+---------------------+-----------+--------+------------+------------+------------+-----------+-----------+--------------+-----------+--------+-------------------+------------------+----------------+------------------+------------------+---------------------+-------------------------+--------------------+----------------+-----------------------------+----------------------+-------------------------+-----------------------+---------------+----------------------+-------------+-------------------+------------------+-------------+----------------+-------------------+----------------------+------------------+---------------+---------------+---------------+----------------------+-------------+--------------------+---------------------+-------------+-----------------+----------------+-------------------------+--------------+--------------------+\n",
      "|201.0|       2|         8|         11|           8|           11|        0.01|Garden Cir|   R|Cameron Park|   CA|          44.6|         41.4|       87.0|       30.06|          10.0|         North|            5.8|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|           Day|           Day|              Day|                  Day|[0.01,44.6,41.4,8...|[-0.1154377452975...|    0.0|           7.0|            1.0|             7.0|              1.0|    6156.0|     0.0|   466.0|      0.0|              19.0|                  3.0|        0.0|     0.0|         0.0|         0.0|         0.0|        0.0|        0.0|           0.0|        0.0|     0.0|                0.0|               0.0|             0.0|               0.0|               0.0|                  0.0|                      0.0|       (2,[0],[1.0])|   (3,[0],[1.0])|                (3,[0],[1.0])|       (24,[19],[1.0])|           (18,[3],[1.0])|          (3,[0],[1.0])|  (3,[0],[1.0])|         (3,[0],[1.0])|(3,[0],[1.0])|(9097,[6156],[1.0])|    (25,[7],[1.0])|(3,[0],[1.0])|   (3,[0],[1.0])|     (13,[1],[1.0])|         (3,[0],[1.0])|     (3,[0],[1.0])|  (3,[0],[1.0])|  (3,[0],[1.0])|  (3,[0],[1.0])|         (3,[0],[1.0])|(3,[0],[1.0])|      (25,[7],[1.0])|       (13,[1],[1.0])|(2,[0],[1.0])|(968,[466],[1.0])|   (3,[0],[1.0])|            (3,[0],[1.0])|(20,[0],[1.0])|(10265,[0,1,2,3,4...|\n",
      "+-----+--------+----------+-----------+------------+-------------+------------+----------+----+------------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+--------------------+--------------------+-------+--------------+---------------+----------------+-----------------+----------+--------+--------+---------+------------------+---------------------+-----------+--------+------------+------------+------------+-----------+-----------+--------------+-----------+--------+-------------------+------------------+----------------+------------------+------------------+---------------------+-------------------------+--------------------+----------------+-----------------------------+----------------------+-------------------------+-----------------------+---------------+----------------------+-------------+-------------------+------------------+-------------+----------------+-------------------+----------------------+------------------+---------------+---------------+---------------+----------------------+-------------+--------------------+---------------------+-------------+-----------------+----------------+-------------------------+--------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                   |label|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(10265,[0,1,2,3,4,5,6,7,34,53,72,91,6259,9200,9669,10171,10192,10200,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.361211368226371,-1.4702415889663176,1.0647461213830427,0.7230555107167154,0.3632274174204553,-0.006063465922271304,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |\n",
      "|(10265,[0,1,2,3,4,5,6,8,31,53,70,91,1103,9201,9338,10171,10192,10205,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.4934208165488596,-1.491003757158492,1.3253799063906717,0.7230555107167154,-0.052638836136874735,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|2    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va2 = VectorAssembler(inputCols=[\"scaledFeatures\",*[c + \"_IDX_vec\" for c in colCat]], outputCol=\"final_features\")\n",
    "\n",
    "temp1 = va2.transform(preprocessed_df)\n",
    "temp1.show(1)\n",
    "temp1 = temp1.withColumn('label', col(\"Severity\"))\n",
    "dataset = temp1.withColumn('features', temp1.final_features).select(\"features\",\"label\")\n",
    "dataset.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChiSqSelector output with top 1 features selected\n",
      "+--------------------+-----+--------------------+\n",
      "|            features|label|    selectedFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.130729...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.130729...|\n",
      "|(10265,[0,1,2,3,4...|    2|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "|(10265,[0,1,2,3,4...|    3|(1,[0],[-0.115437...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ChiSqSelector\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "\n",
    "selector = ChiSqSelector(numTopFeatures=40, featuresCol=\"features\",\n",
    "                         outputCol=\"selectedFeatures\", labelCol=\"label\")\n",
    "\n",
    "result = selector.fit(dataset).transform(dataset)\n",
    "print(\"ChiSqSelector output with top %d features selected\" % selector.getNumTopFeatures())\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                   |label|selectedFeatures              |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------------------+\n",
      "|(10265,[0,1,2,3,4,5,6,7,34,53,72,91,6259,9200,9669,10171,10192,10200,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.361211368226371,-1.4702415889663176,1.0647461213830427,0.7230555107167154,0.3632274174204553,-0.006063465922271304,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,8,31,53,70,91,1103,9201,9338,10171,10192,10205,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.4934208165488596,-1.491003757158492,1.3253799063906717,0.7230555107167154,-0.052638836136874735,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,38,53,79,91,6567,9200,9204,10171,10179,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.2290019199038826,-1.2695406297752971,1.3253799063906717,0.7854722789312323,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,8,38,53,79,91,832,9200,9204,10171,10176,10208,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.361211368226371,-1.4148758071205185,1.3253799063906717,0.7854722789312323,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])    |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,38,53,79,91,359,9200,9605,10171,10188,10208,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10249,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.6256302648713477,-1.767832666387486,1.6294526555662392,0.6918471266094598,0.3632274174204553,-0.006063465922271304,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])   |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,38,53,79,91,544,9200,9204,10171,10176,10208,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10249,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.361211368226371,-1.352589302543995,1.6294526555662392,0.7854722789312323,0.3632274174204553,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])     |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,42,53,80,91,104,9200,9281,10171,10176,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.361211368226371,-1.352589302543995,1.3253799063906717,0.7698680868776017,-0.052638836136874735,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,42,53,80,91,279,9200,9204,10171,10176,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.361211368226371,-1.352589302543995,1.3253799063906717,0.7698680868776017,-0.052638836136874735,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,8,42,53,80,91,163,9200,9204,10171,10176,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.361211368226371,-1.4148758071205185,1.3253799063906717,0.754263894823971,-0.8843713432515348,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])    |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,44,53,82,91,1975,9200,9346,10171,10184,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.3318314908213735,-1.3871929161976193,0.8475513005433517,0.7854722789312323,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,44,53,82,91,163,9200,9302,10171,10194,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.3318314908213735,-1.4425586980434184,1.4991357630624245,0.7698680868776017,0.3632274174204553,-0.006063465922271304,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,44,53,82,91,741,9200,9204,10171,10194,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.3318314908213735,-1.4425586980434184,1.4991357630624245,0.7698680868776017,0.3632274174204553,-0.006063465922271304,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,47,53,82,91,117,9200,9229,10171,10194,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10254,10257,10260,10263],[-0.11543774529750594,-1.3979362149826176,-1.6017353208500897,1.4556967988944864,0.7698680868776017,-1.3002375968088649,0.45719651599119815,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])   |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,29,53,65,91,2362,9201,9850,10171,10194,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10243,10245,10248,10251,10253,10256,10259,10262],[-0.13072997769400937,-1.25838179730888,-1.2972235206981964,1.0213071572151045,0.8634932391993686,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])    |2    |(1,[0],[-0.13072997769400937])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,28,52,65,91,224,9200,9220,10171,10176,10201,10215,10218,10221,10224,10228,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.5448356020076046,-1.5532902617350155,1.4556967988944864,0.8010764709848573,0.3632274174204553,-0.46932344783574076,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])   |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,28,52,66,90,224,9200,9220,10171,10179,10201,10215,10218,10221,10224,10228,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.25838179730888,-1.4702415889663176,0.89099026471129,0.8166806630384879,0.3632274174204553,0.6787556377759009,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])         |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,28,52,66,90,8174,9201,9220,10171,10179,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.13072997769400937,-1.25838179730888,-1.4702415889663176,0.89099026471129,0.8166806630384879,0.3632274174204553,0.6787556377759009,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])        |2    |(1,[0],[-0.13072997769400937])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,28,52,66,90,904,9201,9521,10171,10184,10208,10215,10218,10221,10224,10227,10230,10233,10236,10239,10243,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-2.0222586098388127,-2.1415516938466284,1.6294526555662392,0.8166806630384879,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])   |2    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,7,27,52,67,90,104,9200,9471,10171,10184,10201,10215,10218,10221,10224,10228,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.361211368226371,-1.6778632708880632,0.5869175155357226,0.8634932391993686,0.3632274174204553,1.3837164798181372,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])      |3    |(1,[0],[-0.11543774529750594])|\n",
      "|(10265,[0,1,2,3,4,5,6,17,32,52,71,90,104,9200,9281,10171,10184,10201,10215,10218,10221,10224,10228,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.2290019199038826,-1.491003757158492,0.3697226946960317,0.8478890471457435,0.3632274174204553,1.1420156196893705,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])     |3    |(1,[0],[-0.11543774529750594])|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(1,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet = dataset.randomSplit([0.8 ,0.2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                |label|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|(10265,[0,1,2,3,4,5,6,7,27,52,66,90,105,9200,9477,10171,10176,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.9928787324338153,-2.1138688029237285,1.6294526555662392,1.144368696164675,-1.3002375968088649,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|3    |\n",
      "|(10265,[0,1,2,3,4,5,6,7,27,52,66,90,108,9200,9278,10171,10189,10201,10215,10218,10221,10224,10227,10230,10233,10236,10239,10242,10245,10248,10251,10253,10256,10259,10262],[-0.11543774529750594,-1.6256302648713477,-1.7055461618109624,0.8475513005433517,1.050743543842908,0.3632274174204553,-0.24776432605103804,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |3    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainSet.show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.ml.classification.LogisticRegressionTrainingSummary object at 0x000001E98111BB88>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\",maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(trainSet)\n",
    "trainingSummary = lrModel.summary\n",
    "print(trainingSummary)\n",
    "#print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "#print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "#print(\"RMSE: %s\" % str(trainingSummary.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
