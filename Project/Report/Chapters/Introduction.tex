\documentclass[../main.tex]{subfiles}
\begin{document}
\section{Introduction}
As a part of the course \textit{Big Data Parallel Programming} at Halmstad University a task for processing and analyzing big data is requested through the use of \textit{Apache Spark}. The project is based on information given from the course Parallel Processing Systems for Big Data: A Survey\cite{zhang2016parallel}, Mining of Massive Datasets \cite{leskovec2020mining} and Computer  architecture: a quantitative  approach \cite{hennessy2011computer}. The project focus on extracting Severity from US accidents shared by \textit{A Countrywide Traffic Accident Dataset} \cite{moosavi2019countrywide} and \textit{Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights} \cite{moosavi2019accident}. The dataset consists of a total of 2925212 rows and 47 columns which include information such as coordinates, position, time, weather conditions and location information. The task is to predict Severity of accidents in different areas of the United States and being able to provide an overview of where improvements are needed to increase traffic safety.

In background the different platforms and libraries will be presented as well as previous research on the field of big data. The method contains an explanation of the steps for analysis and preprocessing that have been carried out. In the result section a result is given based on the analysis and preprocessing and finally a discussion and conclusion are given that analyse the presented result. The evaluation and models is created through Jupyter labs.


\end{document}

 